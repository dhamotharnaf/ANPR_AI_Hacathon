{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portable Automatic Number Plate Recognition in Indian Terrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "  1. Classificaiton, couting, tracking and \n",
    "  2. speed detection\n",
    "  3. saving all the images \n",
    "  4. increasing resolution \n",
    "  5. predict number plate \n",
    "  6. saving in database excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2 \n",
    "import math \n",
    "import csv\n",
    "import collections\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "from skimage.filters import threshold_local\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from skimage import measure\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle Tracker, Capture, and Speed Calculation class with member functions respectively\n",
    "y_a = 80\n",
    "y_b = 100\n",
    "y_c = 250\n",
    "y_d = 270\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "        self.et=0\n",
    "        self.s1 = np.zeros((1,1000))\n",
    "        self.s2 = np.zeros((1,1000))\n",
    "        self.s = np.zeros((1,1000))\n",
    "        self.f = np.zeros(1000)\n",
    "        self.capf = np.zeros(1000)\n",
    "        self.count = 0\n",
    "        self.exceeded = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h, index = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 40: \n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    \n",
    "                    objects_bbs_ids.append([x, y, w, h, id, index])\n",
    "                    same_object_detected = True\n",
    "                    \n",
    "                    # start timer s1\n",
    "                    if (y>=y_c and y<=y_d): \n",
    "                        self.s1[0,id] = time.time() \n",
    "                        \n",
    "                    # stop timer and find difference \n",
    "                    if (y>=y_a and y<=y_b): \n",
    "                        self.s2[0, id] = time.time() \n",
    "                        self.s[0,id] = self.s2[0,id] - self.s1[0,id]\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n",
    "                self.id_count += 1\n",
    "                self.s[0,self.id_count] = 0 \n",
    "                self.s1[0,self.id_count] = 0 \n",
    "                self.s2[0,self.id_count] = 0\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id, index = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "            \n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n",
    "    def getsp(self,id): \n",
    "        if (self.s[0,id] != 0): \n",
    "            #s = 214.15/ self.s[0, id]\n",
    "            s = 10000000000/ self.s[0, id]\n",
    "            s = s * 3\n",
    "        else: \n",
    "            s = 0\n",
    "        return int(s)\n",
    "\n",
    "    def capture(self,img,x,y,h,w,sp,id):\n",
    "        if(self.capf[id]==0):\n",
    "            self.capf[id] = 1\n",
    "            self.f[id]=0\n",
    "            crop_img = img[y-5:y + h+5, x-5:x + w+5]\n",
    "            n = str(id)+\"_speed_\"+str(sp)\n",
    "            file =  './'+n+'.jpg'\n",
    "            cv2.imwrite(file, crop_img)\n",
    "            self.count += 1\n",
    " \n",
    "    \n",
    "    def limit(self): \n",
    "        return limit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to save the video file in the current directory \n",
      "Enter the video path here: video.MOV\n"
     ]
    }
   ],
   "source": [
    "print(\"Try to save the video file in the current directory \")\n",
    "vidpath = input(\"Enter the video path here: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification, Tracking, Counting, Speed Detection, and Saving in Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "limit = 70\n",
    "\n",
    "# Initialize the videocapture object\n",
    "cap = cv2.VideoCapture(vidpath)\n",
    "#input_size = 415\n",
    "\n",
    "# Detection confidence threshold\n",
    "confThreshold =0.2\n",
    "nmsThreshold= 0.2\n",
    "\n",
    "font_color = (0, 0, 255)\n",
    "font_size = 0.5\n",
    "font_thickness = 2\n",
    "\n",
    "# Middle cross line position\n",
    "middle_line_position = 225   \n",
    "up_line_position = 90\n",
    "down_line_position = 260\n",
    "\n",
    "\n",
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "\n",
    "\n",
    "# class index for our required detection classes\n",
    "required_class_index = [2, 3, 5, 7]\n",
    "\n",
    "detected_classNames = []\n",
    "\n",
    "## Model Files\n",
    "modelConfiguration = 'yolov3-320.cfg'\n",
    "modelWeigheights = 'yolov3-320.weights'\n",
    "\n",
    "# configure the network model\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)\n",
    "\n",
    "# Configure the network backend\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random colour for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n",
    "\n",
    "# Function for finding the center of a rectangle\n",
    "def find_center(x, y, w, h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy=y+y1\n",
    "    return cx, cy\n",
    "    \n",
    "# List for store vehicle count information\n",
    "temp_up_list = []\n",
    "temp_down_list = []\n",
    "up_list = [0, 0, 0, 0]\n",
    "down_list = [0, 0, 0, 0]\n",
    "\n",
    "# Function for count vehicle\n",
    "def count_vehicle(box_id, img):\n",
    "\n",
    "    x, y, w, h, id, index = box_id\n",
    "            \n",
    "   \n",
    "        \n",
    "\n",
    "    # Find the center of the rectangle for detection\n",
    "    center = find_center(x, y, w, h)\n",
    "    ix, iy = center\n",
    "    \n",
    "    # Find the current position of the vehicle\n",
    "    if (iy > up_line_position) and (iy < middle_line_position):\n",
    "\n",
    "        if id not in temp_up_list:\n",
    "            temp_up_list.append(id)\n",
    "\n",
    "    elif iy < down_line_position and iy > middle_line_position:\n",
    "        if id not in temp_down_list:\n",
    "            temp_down_list.append(id)\n",
    "            \n",
    "    elif iy < up_line_position:\n",
    "        if id in temp_down_list:\n",
    "            temp_down_list.remove(id)\n",
    "            up_list[index] = up_list[index]+1\n",
    "\n",
    "    elif iy > down_line_position:\n",
    "        if id in temp_up_list:\n",
    "            temp_up_list.remove(id)\n",
    "            down_list[index] = down_list[index] + 1\n",
    "\n",
    "    # Draw circle in the middle of the rectangle\n",
    "    cv2.circle(img, center, 2, (0, 0, 255), -1)  # end here\n",
    "\n",
    "\n",
    "# Function for finding the detected objects from the network output\n",
    "def postProcess(outputs,img):\n",
    "    global detected_classNames , detection, boxes_ids, s, name, confidence_scores\n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if classId in required_class_index:\n",
    "                if confidence > confThreshold:\n",
    "                    \n",
    "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
    "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    classIds.append(classId)\n",
    "                    confidence_scores.append(float(confidence))\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "    \n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "        \n",
    "\n",
    "        color = [int(c) for c in colors[classIds[i]]]\n",
    "        name = classNames[classIds[i]]\n",
    "        detected_classNames.append(name)\n",
    "\n",
    "        # Draw classname and confidence score \n",
    "        cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',(x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Draw bounding rectangle\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "        detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "        \n",
    "    # Update the tracker for each object\n",
    "\n",
    "\n",
    "def realTime():\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "        ih, iw, channels = img.shape\n",
    "        input_size = iw - ih - 5 \n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "        # Set the input of the network\n",
    "        net.setInput(blob)\n",
    "        layersNames = net.getLayerNames()\n",
    "        outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "        # Feed data to the network\n",
    "        outputs = net.forward(outputNames)\n",
    "      \n",
    "    \n",
    "        # Find the objects from the network output\n",
    "        postProcess(outputs,img)\n",
    "        boxes_ids = tracker.update(detection)\n",
    "        speed_lst = []\n",
    "        for box_id in boxes_ids:\n",
    "            count_vehicle(box_id, img)\n",
    "            x,y,w,h,id,index = box_id\n",
    "        \n",
    "            s = tracker.getsp(id)\n",
    "            speed_lst.append(s)\n",
    "            \n",
    "            text= \"       id:\"+str(id)+' speed:'+str(s)+'Km/h'\n",
    "\n",
    "\n",
    "\n",
    "            if(tracker.getsp(id)<limit):\n",
    "                cv2.putText(img,text,(x+30,y-10), cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,0),1)\n",
    "\n",
    "            else:\n",
    "                cv2.putText(img,text,(x+30, y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 255),1)\n",
    "\n",
    "            s = tracker.getsp(id)\n",
    "            if (tracker.f[id] == 1):\n",
    "                tracker.capture(img, x, y, h, w, s, id)\n",
    "\n",
    "        # Show the frames\n",
    "        cv2.imshow('Output', img)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Write the vehicle counting information in a file and save it\n",
    "\n",
    "    with open(\"data.csv\", 'w') as f1:\n",
    "        cwriter = csv.writer(f1)\n",
    "        cwriter.writerow(['Direction', 'car', 'motorbike', 'bus', 'truck'])\n",
    "        up_list.insert(0, \"Up\")\n",
    "        down_list.insert(0, \"Down\")\n",
    "        speed_lst.insert(0, \"Speed\")\n",
    "        boxes_ids.insert(0,\"ID\")\n",
    "        cwriter.writerow(up_list)\n",
    "        cwriter.writerow(down_list)\n",
    "        cwriter.writerow(speed_lst)\n",
    "        cwriter.writerow(boxes_ids)\n",
    "        f1.close()\n",
    "    \n",
    "    # Finally realese the capture object and destroy all active windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    realTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number Plate Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-efa31079885e>:32: UserWarning: The argument 'neighbors' is deprecated and will be removed in scikit-image 0.18, use 'connectivity' instead. For neighbors=8, use connectivity=2\n",
      "  labels = measure.label(thresh, neighbors=8, background=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28A33185\n",
      "29A33185\n",
      "29A33185\n",
      "29A33185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def sort_cont(character_contours):\n",
    "    \"\"\"\n",
    "    To sort contours from left to right\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in character_contours]\n",
    "    (character_contours, boundingBoxes) = zip(*sorted(zip(character_contours, boundingBoxes),\n",
    "                                                      key=lambda b: b[1][i], reverse=False))\n",
    "    return character_contours\n",
    "\n",
    "\n",
    "def segment_chars(plate_img, fixed_width):\n",
    "    \"\"\"\n",
    "    extract Value channel from the HSV format of image and apply adaptive thresholding\n",
    "    to reveal the characters on the license plate\n",
    "    \"\"\"\n",
    "    V = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]\n",
    "\n",
    "    T = threshold_local(V, 29, offset=15, method='gaussian')\n",
    "\n",
    "    thresh = (V > T).astype('uint8') * 255\n",
    "\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # resize the license plate region to a canoncial size\n",
    "    plate_img = imutils.resize(plate_img, width=fixed_width)\n",
    "    thresh = imutils.resize(thresh, width=fixed_width)\n",
    "    bgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # perform a connected components analysis and initialize the mask to store the locations\n",
    "    # of the character candidates\n",
    "    labels = measure.label(thresh, neighbors=8, background=0)\n",
    "\n",
    "    charCandidates = np.zeros(thresh.shape, dtype='uint8')\n",
    "\n",
    "    # loop over the unique components\n",
    "    characters = []\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask to display only connected components for the\n",
    "        # current label, then find contours in the label mask\n",
    "        labelMask = np.zeros(thresh.shape, dtype='uint8')\n",
    "        labelMask[labels == label] = 255\n",
    "\n",
    "        cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[1] if imutils.is_cv2() else cnts[0]\n",
    "\n",
    "        # ensure at least one contour was found in the mask\n",
    "        if len(cnts) > 0:\n",
    "\n",
    "            # grab the largest contour which corresponds to the component in the mask, then\n",
    "            # grab the bounding box for the contour\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)\n",
    "\n",
    "            # compute the aspect ratio, solodity, and height ration for the component\n",
    "            aspectRatio = boxW / float(boxH)\n",
    "            solidity = cv2.contourArea(c) / float(boxW * boxH)\n",
    "            heightRatio = boxH / float(plate_img.shape[0])\n",
    "\n",
    "            # determine if the aspect ratio, solidity, and height of the contour pass\n",
    "            # the rules tests\n",
    "            keepAspectRatio = aspectRatio < 1.0\n",
    "            keepSolidity = solidity > 0.15\n",
    "            keepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
    "\n",
    "            # check to see if the component passes all the tests\n",
    "            if keepAspectRatio and keepSolidity and keepHeight and boxW > 14:\n",
    "                # compute the convex hull of the contour and draw it on the character\n",
    "                # candidates mask\n",
    "                hull = cv2.convexHull(c)\n",
    "\n",
    "                cv2.drawContours(charCandidates, [hull], -1, 255, -1)\n",
    "\n",
    "    contours, hier = cv2.findContours(charCandidates, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        contours = sort_cont(contours)\n",
    "        addPixel = 4  # value to be added to each dimension of the character\n",
    "        for c in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            if y > addPixel:\n",
    "                y = y - addPixel\n",
    "            else:\n",
    "                y = 0\n",
    "            if x > addPixel:\n",
    "                x = x - addPixel\n",
    "            else:\n",
    "                x = 0\n",
    "            temp = bgr_thresh[y:y + h + (addPixel * 2), x:x + w + (addPixel * 2)]\n",
    "\n",
    "            characters.append(temp)\n",
    "        return characters\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "class PlateFinder:\n",
    "    def __init__(self):\n",
    "        self.min_area = 4500  # minimum area of the plate\n",
    "        self.max_area = 30000  # maximum area of the plate\n",
    "\n",
    "        self.element_structure = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=(22, 3))\n",
    "\n",
    "    def preprocess(self, input_img):\n",
    "        imgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)  # old window was (5,5)\n",
    "        gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)  # convert to gray\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3)  # sobelX to get the vertical edges\n",
    "        ret2, threshold_img = cv2.threshold(sobelx, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        element = self.element_structure\n",
    "        morph_n_thresholded_img = threshold_img.copy()\n",
    "        cv2.morphologyEx(src=threshold_img, op=cv2.MORPH_CLOSE, kernel=element, dst=morph_n_thresholded_img)\n",
    "        return morph_n_thresholded_img\n",
    "\n",
    "    def extract_contours(self, after_preprocess):\n",
    "        contours, _ = cv2.findContours(after_preprocess, mode=cv2.RETR_EXTERNAL,\n",
    "                                                    method=cv2.CHAIN_APPROX_NONE)\n",
    "        return contours\n",
    "\n",
    "    def clean_plate(self, plate):\n",
    "        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        if contours:\n",
    "            areas = [cv2.contourArea(c) for c in contours]\n",
    "            max_index = np.argmax(areas)  # index of the largest contour in the area array\n",
    "\n",
    "            max_cnt = contours[max_index]\n",
    "            max_cntArea = areas[max_index]\n",
    "            x, y, w, h = cv2.boundingRect(max_cnt)\n",
    "            rect = cv2.minAreaRect(max_cnt)\n",
    "            rotatedPlate = plate\n",
    "            if not self.ratioCheck(max_cntArea, rotatedPlate.shape[1], rotatedPlate.shape[0]):\n",
    "                return plate, False, None\n",
    "            return rotatedPlate, True, [x, y, w, h]\n",
    "        else:\n",
    "            return plate, False, None\n",
    "\n",
    "\n",
    "\n",
    "    def check_plate(self, input_img, contour):\n",
    "        min_rect = cv2.minAreaRect(contour)\n",
    "        if self.validateRatio(min_rect):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            after_validation_img = input_img[y:y + h, x:x + w]\n",
    "            after_clean_plate_img, plateFound, coordinates = self.clean_plate(after_validation_img)\n",
    "            if plateFound:\n",
    "                characters_on_plate = self.find_characters_on_plate(after_clean_plate_img)\n",
    "                if (characters_on_plate is not None and len(characters_on_plate) == 8):\n",
    "                    x1, y1, w1, h1 = coordinates\n",
    "                    coordinates = x1 + x, y1 + y\n",
    "                    after_check_plate_img = after_clean_plate_img\n",
    "                    return after_check_plate_img, characters_on_plate, coordinates\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "\n",
    "    def find_possible_plates(self, input_img):\n",
    "        \"\"\"\n",
    "        Finding all possible contours that can be plates\n",
    "        \"\"\"\n",
    "        plates = []\n",
    "        self.char_on_plate = []\n",
    "        self.corresponding_area = []\n",
    "\n",
    "        self.after_preprocess = self.preprocess(input_img)\n",
    "        possible_plate_contours = self.extract_contours(self.after_preprocess)\n",
    "\n",
    "        for cnts in possible_plate_contours:\n",
    "            plate, characters_on_plate, coordinates = self.check_plate(input_img, cnts)\n",
    "            if plate is not None:\n",
    "                plates.append(plate)\n",
    "                self.char_on_plate.append(characters_on_plate)\n",
    "                self.corresponding_area.append(coordinates)\n",
    "\n",
    "        if (len(plates) > 0):\n",
    "            return plates\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_characters_on_plate(self, plate):\n",
    "\n",
    "        charactersFound = segment_chars(plate, 400)\n",
    "        if charactersFound:\n",
    "            return charactersFound\n",
    "\n",
    "    # PLATE FEATURES\n",
    "    def ratioCheck(self, area, width, height):\n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "\n",
    "        ratioMin = 3\n",
    "        ratioMax = 6\n",
    "\n",
    "        ratio = float(width) / float(height)\n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "\n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def preRatioCheck(self, area, width, height):\n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "\n",
    "        ratioMin = 2.5\n",
    "        ratioMax = 7\n",
    "\n",
    "        ratio = float(width) / float(height)\n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "\n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def validateRatio(self, rect):\n",
    "        (x, y), (width, height), rect_angle = rect\n",
    "\n",
    "        if (width > height):\n",
    "            angle = -rect_angle\n",
    "        else:\n",
    "            angle = 90 + rect_angle\n",
    "\n",
    "        if angle > 15:\n",
    "            return False\n",
    "        if (height == 0 or width == 0):\n",
    "            return False\n",
    "\n",
    "        area = width * height\n",
    "        if not self.preRatioCheck(area, width, height):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.model_file = \"binary_128_0.50_ver3.pb\"\n",
    "        self.label_file = \"binary_128_0.50_labels_ver2.txt\"\n",
    "        self.label = self.load_label(self.label_file)\n",
    "        self.graph = self.load_graph(self.model_file)\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "\n",
    "    def load_graph(self, modelFile):\n",
    "        graph = tf.Graph()\n",
    "        graph_def = tf.compat.v1.GraphDef() \n",
    "        with open(modelFile, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        with graph.as_default():\n",
    "            tf.import_graph_def(graph_def)\n",
    "        return graph\n",
    "\n",
    "    def load_label(self, labelFile):\n",
    "        label = []\n",
    "        proto_as_ascii_lines = tf.compat.v2.io.gfile.GFile(labelFile).readlines()\n",
    "        for l in proto_as_ascii_lines:\n",
    "            label.append(l.rstrip())\n",
    "        return label\n",
    "\n",
    "    def convert_tensor(self, image, imageSizeOuput):\n",
    "        \"\"\"\n",
    "    takes an image and tranform it in tensor\n",
    "    \"\"\"\n",
    "        image = cv2.resize(image, dsize=(imageSizeOuput, imageSizeOuput), interpolation=cv2.INTER_CUBIC)\n",
    "        np_image_data = np.asarray(image)\n",
    "        np_image_data = cv2.normalize(np_image_data.astype('float'), None, -0.5, .5, cv2.NORM_MINMAX)\n",
    "        np_final = np.expand_dims(np_image_data, axis=0)\n",
    "        return np_final\n",
    "\n",
    "    def label_image(self, tensor):\n",
    "\n",
    "        input_name = \"import/input\"\n",
    "        output_name = \"import/final_result\"\n",
    "\n",
    "        input_operation = self.graph.get_operation_by_name(input_name)\n",
    "        output_operation = self.graph.get_operation_by_name(output_name)\n",
    "\n",
    "        results = self.sess.run(output_operation.outputs[0],\n",
    "                                {input_operation.outputs[0]: tensor})\n",
    "        results = np.squeeze(results)\n",
    "        labels = self.label\n",
    "        top = results.argsort()[-1:][::-1]\n",
    "        return labels[top[0]]\n",
    "\n",
    "    def label_image_list(self, listImages, imageSizeOuput):\n",
    "        plate = \"\"\n",
    "        for img in listImages:\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            plate = plate + self.label_image(self.convert_tensor(img, imageSizeOuput))\n",
    "        return plate, len(plate)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    findPlate = PlateFinder()\n",
    "    global plate_numbers\n",
    "    # Initialize the Neural Network\n",
    "    model = NeuralNetwork()\n",
    "    plate_numbers = []\n",
    "    cap = cv2.VideoCapture(videopath)\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('original video', img)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            # cv2.waitKey(0)\n",
    "            possible_plates = findPlate.find_possible_plates(img)\n",
    "            if possible_plates is not None:\n",
    "                for i, p in enumerate(possible_plates):\n",
    "                    chars_on_plate = findPlate.char_on_plate[i]\n",
    "                    recognized_plate, _ = model.label_image_list(chars_on_plate, imageSizeOuput=128)\n",
    "                    print(recognized_plate)\n",
    "                    plate_numbers.append(recognized_plate)\n",
    "                    cv2.imshow('plate', p)\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Please enter the correct video file name\")\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading To Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_csv():\n",
    "    with open(\"data.csv\", 'w') as f1:\n",
    "        cwriter = csv.writer(f1)\n",
    "        cwriter.writerow(['Direction', 'car', 'motorbike', 'bus', 'truck'])\n",
    "        up_list.insert(0, \"Up\")\n",
    "        down_list.insert(0, \"Down\")\n",
    "        cwriter.writerow(up_list)\n",
    "        cwriter.writerow(down_list)\n",
    "        f1.close()\n",
    "        \n",
    "    temp_dict = {'ID': boxes_ids,'Speed':speed_lst,'Plate_Number':plate_numbers}\n",
    "    df = pd.DataFrame(temp_dict)\n",
    "    df.to_csv('data2.csv')\n",
    "\n",
    "def upload_table(path, filename, delim, cursor):\n",
    "    \"\"\"\n",
    "    Function to upload flat file to sqlserver\n",
    "    \"\"\"\n",
    "    tbl = filename.split('.')[0]\n",
    "    cnt = 0\n",
    "    with open (path + filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=delim)\n",
    "        for row in reader:\n",
    "            row.pop() # can be commented out\n",
    "            row = ['NULL' if val == '' else val for val in row]\n",
    "            row = [x.replace(\"'\", \"''\") for x in row]\n",
    "            out = \"'\" + \"', '\".join(str(item) for item in row) + \"'\"\n",
    "            out = out.replace(\"'NULL'\", 'NULL')\n",
    "            query = \"INSERT INTO \" + tbl + \" VALUES (\" + out + \")\"\n",
    "            cursor.execute(query)\n",
    "            cnt = cnt + 1\n",
    "            if cnt % 10000 == 0:\n",
    "                cursor.commit()\n",
    "        cursor.commit()\n",
    "    print(\"Uploaded \" + str(cnt) + \" rows into table \" + tbl + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF THE IMAGE  RESOLUTION IS LOWER\n",
    "## Super Resolution ESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./image_enhancing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Plate Detection Again on a Single Image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "img_path = None\n",
    "img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "img = cv2.resize(img, (600,400) )\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "gray = cv2.bilateralFilter(gray, 13, 15, 15) \n",
    "\n",
    "edged = cv2.Canny(gray, 30, 200) \n",
    "contours = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = imutils.grab_contours(contours)\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
    "screenCnt = None\n",
    "\n",
    "for c in contours:\n",
    "    \n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n",
    " \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "if screenCnt is None:\n",
    "    detected = 0\n",
    "    print (\"No contour detected\")\n",
    "else:\n",
    "     detected = 1\n",
    "\n",
    "if detected == 1:\n",
    "    cv2.drawContours(img, [screenCnt], -1, (0, 0, 255), 3)\n",
    "\n",
    "mask = np.zeros(gray.shape,np.uint8)\n",
    "new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)\n",
    "new_image = cv2.bitwise_and(img,img,mask=mask)\n",
    "\n",
    "(x, y) = np.where(mask == 255)\n",
    "(topx, topy) = (np.min(x), np.min(y))\n",
    "(bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "Cropped = gray[topx:bottomx+1, topy:bottomy+1]\n",
    "\n",
    "text = pytesseract.image_to_string(Cropped, config='--psm 11')\n",
    "print(\"programming_fever's License Plate Recognition\\n\")\n",
    "print(\"Detected license plate Number is:\",text)\n",
    "img = cv2.resize(img,(500,300))\n",
    "Cropped = cv2.resize(Cropped,(400,200))\n",
    "cv2.imshow('car',img)\n",
    "cv2.imshow('Cropped',Cropped)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
